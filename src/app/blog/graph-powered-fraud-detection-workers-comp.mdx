---
title: "Graph-Powered Fraud Detection: Building a Modern Workers' Comp System"
excerpt: "A deep dive into architecting a next-generation workers' compensation fraud detection system using graph databases, LLMs, and real-time analytics to catch sophisticated fraud rings that traditional systems miss."
date: "2025-01-06"
category: "System Architecture"
tags: ["Graph Databases", "AI & Machine Learning", "System Design", "Fraud Detection"]
readTime: "15 min read"
---

# Graph-Powered Fraud Detection: Building a Modern Workers' Comp System

Workers' compensation fraud costs the industry $7.2 billion annually in the US alone. Traditional detection systems, built on rigid rules and siloed data, catch only the most obvious cases while sophisticated fraud rings operate with impunity. 

What if we could build a system that thinks like an investigator—connecting dots across seemingly unrelated claims, understanding narratives, and uncovering hidden relationships? Here's how to architect a modern fraud detection platform that combines graph databases, LLMs, and real-time analytics to catch what others miss.

## The Problem with Traditional Fraud Detection

Current workers' comp fraud detection systems suffer from fundamental limitations:

1. **Siloed Data**: Claims, medical records, and external data live in separate systems with no meaningful connections
2. **Rule-Based Detection**: Static rules catch only known patterns—fraudsters simply evolve their tactics
3. **No Network Analysis**: Systems evaluate claims in isolation, missing organized fraud rings
4. **Manual Investigation**: Investigators waste time on false positives while sophisticated schemes go undetected

The result? A reactive system that's always playing catch-up. We need a fundamentally different approach.

## Architecture Overview: A Graph-First Approach

The key insight: fraud is fundamentally about relationships. A doctor treating multiple "injured" workers from the same law firm. A claimant whose social media shows them playing sports while claiming total disability. An address shared by dozens of unrelated claimants.

Here's the complete system architecture:

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Claims Data   │    │  Medical Data   │    │   OSINT Data    │
│                 │    │                 │    │                 │
│ • Claim forms   │    │ • Doctor visits │    │ • Social media  │
│ • Injury reports│    │ • Medical bills │    │ • Public records│
│ • Photos/docs   │    │ • Treatment     │    │ • Court filings │
│ • Witness stmt  │    │ • Prescriptions │    │ • Property recs │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
                    ┌─────────────────┐
                    │  Data Lake      │
                    │                 │
                    │ • Raw files     │
                    │ • Streaming     │
                    │ • Batch loads   │
                    │ • Change logs   │
                    └─────────────────┘
```

## The Power of Entity Resolution

The magic starts with entity resolution. Raw data is messy—people use nicknames, move addresses, change phone numbers. Traditional systems treat "Bob Smith" and "Robert Smith Jr." as different people. Ours doesn't.

### LLM-Powered Processing Pipeline
```
Raw Data → Entity Extraction → Fuzzy Matching → Graph Loading
    ↓              ↓               ↓              ↓
┌─────────┐  ┌─────────────┐  ┌──────────┐  ┌─────────┐
│ Text    │  │ Extract:    │  │ Match:   │  │ Create  │
│ Mining  │  │ • Names     │  │ • People │  │ Nodes & │
│ (LLM)   │  │ • Addresses │  │ • Places │  │ Edges   │
│         │  │ • Dates     │  │ • Orgs   │  │         │
└─────────┘  └─────────────┘  └──────────┘  └─────────┘
```

We use LLMs to extract entities from unstructured text—claim narratives, medical notes, witness statements. Then we apply fuzzy matching algorithms to link entities across data sources. "Dr. John Martinez" at "123 Main St" becomes connected to "J. Martinez, MD" at "123 Main Street Suite 100."

## Graph Database: Where Connections Reveal Truth

At the heart of our system lies Neo4j, storing entities and their relationships:

```cypher
(Person)-[:LIVES_AT]->(Address)
(Person)-[:EMPLOYED_BY]->(Company)
(Person)-[:FILED_CLAIM]->(Claim)
(Person)-[:TREATED_BY]->(Doctor)
(Person)-[:KNOWS]->(Person)
(Doctor)-[:LOCATED_AT]->(Address)
(Claim)-[:OCCURRED_AT]->(Location)
(Claim)-[:INVOLVES]->(BodyPart)
(Address)-[:WITHIN]->(GeographicRegion)
```

Each relationship carries metadata: confidence scores, temporal data, source attribution. This isn't just data storage—it's a knowledge graph that grows smarter with every claim.

## Real-Time Analytics: Finding Fraud Patterns

The graph enables powerful real-time analytics:

### 1. Community Detection
Using algorithms like Louvain and Label Propagation, we identify clusters of connected entities. A "community" of claimants, doctors, and lawyers with unusual connection patterns? That's a potential fraud ring.

### 2. Centrality Analysis
PageRank and Betweenness Centrality reveal key players. The lawyer who appears in multiple suspicious claims? The doctor whose patients have statistically improbable injury patterns? They bubble to the top.

### 3. Path Analysis
Trace connections between entities. Two claimants seem unrelated until you discover they're both connected to the same physical therapy clinic, which shares an owner with a law firm specializing in workers' comp cases.

### 4. Temporal Patterns
Time-based analysis reveals suspicious sequences. Multiple "slip and fall" injuries at the same company within days? Claims that spike before holiday weekends? The patterns emerge.

## LLM Services: Understanding Context

While the graph reveals connections, LLMs understand context:

```
┌─────────────────────────────────────────────────────────┐
│                 LLM Service Layer                       │
├─────────────────┬─────────────────┬─────────────────────┤
│ Entity          │ Anomaly         │ Narrative           │
│ Extraction      │ Detection       │ Analysis            │
│                 │                 │                     │
│ • Named Entity  │ • Pattern       │ • Inconsistency     │
│   Recognition   │   Recognition   │   Detection         │
│ • Relationship  │ • Outlier       │ • Sentiment        │
│   Extraction    │   Scoring       │   Analysis          │
│ • Data          │ • Risk          │ • Story             │
│   Normalization │   Assessment    │   Coherence         │
└─────────────────┴─────────────────┴─────────────────────┘
```

### Narrative Analysis
LLMs analyze claim narratives for inconsistencies. A claimant describes "severe back pain preventing any movement" but their medical exam notes "patient walked into office unassisted." The system flags the discrepancy.

### Pattern Recognition
Fine-tuned models learn fraud patterns from historical data. They recognize suspicious language patterns, unusual claim sequences, and anomalous medical treatment paths.

### Semantic Search
Vector embeddings enable semantic similarity search. Find all claims with narratives similar to known fraud cases, even if they use different wording.

## Fraud Scoring: Combining Signals

No single signal proves fraud. Our scoring engine combines multiple dimensions:

```
Final Risk Score = w₁(Graph_Score) + w₂(LLM_Score) + w₃(Historical_Score) + w₄(External_Score)

Where:
• Graph_Score: Network analysis results
• LLM_Score: Narrative and anomaly detection
• Historical_Score: Pattern matching against known fraud
• External_Score: OSINT validation results
```

The weights adapt based on claim type, amount, and historical accuracy. A machine learning model continuously refines these weights based on investigation outcomes.

## Integration Layer: Seamless Operations

The system exposes RESTful APIs for seamless integration:

```
┌─────────────────────────────────────────────────────┐
│                  API Gateway                        │
├─────────────┬─────────────┬─────────────┬──────────┤
│ Claims API  │ Graph API   │ Analytics   │ Admin    │
│             │             │ API         │ API      │
│ • Submit    │ • Query     │ • Score     │ • Config │
│   new claim │   entities  │   claim     │ • Users  │
│ • Update    │ • Find      │ • Generate  │ • Audit  │
│   status    │   patterns  │   report    │   logs   │
│ • Retrieve  │ • Add       │ • Historical│          │
│   history   │   evidence  │   trends    │          │
└─────────────┴─────────────┴─────────────┴──────────┘
```

Claims adjusters access a React dashboard showing risk scores, relationship graphs, and investigation recommendations. The system integrates with existing claims management platforms via webhooks and batch processing.

## Infrastructure: Built for Scale

The cloud-native architecture handles enterprise workloads:

```
┌─────────────────────────────────────────────────────┐
│                 Load Balancer                       │
└─────────────────┬───────────────────────────────────┘
                  │
    ┌─────────────┼─────────────┐
    │             │             │
┌─────────┐  ┌─────────┐  ┌─────────┐
│ Web     │  │ API     │  │ ML      │
│ Tier    │  │ Tier    │  │ Tier    │
│         │  │         │  │         │
│ React   │  │ FastAPI │  │ GPUs    │
│ Dashboard│  │ Services│  │ LLM     │
└─────────┘  └─────────┘  └─────────┘
     │             │             │
     └─────────────┼─────────────┘
                   │
    ┌──────────────┴──────────────┐
    │         Data Tier           │
    ├─────────────┬───────────────┤
    │ Neo4j       │ Data Lake     │
    │ Cluster     │ (S3/ADLS)     │
    └─────────────┴───────────────┘
```

Key components:
- **Apache Kafka**: Real-time claim streaming
- **Apache Airflow**: Batch processing orchestration  
- **Redis**: Caching for frequently accessed graph queries
- **Delta Lake**: Versioned data storage with ACID transactions

## Security & Compliance: Enterprise-Ready

Healthcare data demands rigorous security:

- **Encryption**: AES-256 at rest, TLS 1.3 in transit
- **Access Control**: Role-based with attribute permissions
- **Audit Logging**: Complete trail of all data access
- **Privacy**: Differential privacy for aggregate queries
- **Compliance**: HIPAA-compliant infrastructure

## The Business Impact

This isn't just elegant architecture—it delivers measurable results:

1. **Catch Sophisticated Fraud**: Network analysis reveals organized rings that rule-based systems miss
2. **Reduce False Positives**: Better scoring means investigators focus on real fraud
3. **Faster Detection**: Real-time analysis catches fraud before payments go out
4. **Continuous Improvement**: The system learns from every investigation

Conservative estimates suggest a 10-15% reduction in fraud losses. For a mid-sized insurer, that's $50-100 million in annual savings.

## Looking Forward

The future of fraud detection isn't about better rules—it's about understanding relationships, context, and patterns at scale. By combining graph databases with LLMs, we create a system that thinks like an investigator but operates at machine speed.

This architecture represents a fundamental shift in how we approach fraud detection. Instead of playing catch-up with increasingly sophisticated fraudsters, we're building systems that stay ahead of the curve.

The technology exists today. The data is available. The only question is: how long will insurers continue losing billions to fraud that modern systems could prevent?

---

*Interested in implementing a similar system? The architecture scales from mid-market insurers to nation-wide carriers. The key is starting with a focused pilot—perhaps suspicious provider networks or high-value claims—then expanding based on proven ROI.*
